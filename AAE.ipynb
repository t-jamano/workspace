{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "from keras import backend as K\n",
    "K.set_session(session)\n",
    "\n",
    "from Utils import *\n",
    "from Models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('/work/data/bpe/en.wiki.bpe.op50000.model')\n",
    "bpe = KeyedVectors.load_word2vec_format(\"/work/data/bpe/en.wiki.bpe.op50000.d200.w2v.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run = AAE(100,10, bpe.get_keras_embedding(True), [5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10/10 [==============================] - 6s 571ms/step - loss: 56.7637 - decoder_loss: 28.3834 - decoder_xpred_loss: 28.3674 - decoder_yfake_loss: 0.6858 - decoder_yreal_loss: 0.9159 - discriminator_loss: 28.3803 - discriminator_xpred_loss: 28.3674 - discriminator_yfake_loss: 0.7329 - discriminator_yreal_loss: 0.5601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd3c7196630>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(10, size=(10,10))\n",
    "y = np.random.randint(10, size=(10,10,100))\n",
    "valid = np.ones(10)\n",
    "fake = np.zeros(10)\n",
    "run.model.fit(x, [y, valid, fake, y, fake, valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras_adversarial.legacy import l1l2\n",
    "from keras_adversarial import AdversarialModel, fix_names, n_choice\n",
    "from keras_adversarial import AdversarialOptimizerSimultaneous, normal_latent_sampling\n",
    "from keras.layers import LeakyReLU, Activation\n",
    "import os\n",
    "\n",
    "class AAE(object):\n",
    "    def __init__(self, nb_words, max_len, emb, dim, comp_topk=None, ctype=None, epsilon_std=1.0, save_model='best_model'):\n",
    "        self.dim = dim\n",
    "        self.comp_topk = comp_topk\n",
    "        self.ctype = ctype\n",
    "        self.epsilon_std = epsilon_std\n",
    "        self.save_model = save_model\n",
    "\n",
    "        self.nb_words = nb_words\n",
    "        self.max_len = max_len\n",
    "        self.emb = emb\n",
    "\n",
    "        self.decoder = self.create_decoder()\n",
    "        self.encoder = self.create_encoder()\n",
    "        autoencoder = Model(self.encoder.inputs, self.decoder(self.encoder(self.encoder.inputs)))\n",
    "        discriminator = self.create_discriminator()\n",
    "\n",
    "        x = self.encoder.inputs[0]\n",
    "        z = self.encoder(x)\n",
    "        xpred = self.decoder(z)\n",
    "        zreal = normal_latent_sampling((self.dim[1],))(x)\n",
    "        yreal = discriminator(zreal)\n",
    "        yfake = discriminator(z)\n",
    "        aae = Model(x, fix_names([xpred, yfake, yreal], [\"xpred\", \"yfake\", \"yreal\"]))\n",
    "        \n",
    "        generative_params = self.decoder.trainable_weights + self.encoder.trainable_weights\n",
    "        \n",
    "        self.model = AdversarialModel(base_model=aae,\n",
    "                                 player_params=[generative_params, discriminator.trainable_weights],\n",
    "                                 player_names=[\"decoder\", \"discriminator\"])\n",
    "        self.model.adversarial_compile(adversarial_optimizer=AdversarialOptimizerSimultaneous(),\n",
    "                                  player_optimizers=[Adam(1e-4, decay=1e-4), Adam(1e-3, decay=1e-4)],\n",
    "                                  loss={\"yfake\": \"binary_crossentropy\", \"yreal\": \"binary_crossentropy\",\n",
    "                                    \"xpred\": \"mean_squared_error\"},\n",
    "                              player_compile_kwargs=[{\"loss_weights\": {\"yfake\": 1e-2, \"yreal\": 1e-2, \"xpred\": 1}}] * 2)\n",
    "\n",
    "    def create_discriminator(self):\n",
    "\n",
    "        z = Input((self.dim[1],))\n",
    "        h = z\n",
    "        h = Dense(self.dim[0], name=\"discriminator_h1\")(h)\n",
    "        h = LeakyReLU(0.2)(h)\n",
    "        h = Dense(self.dim[1], name=\"discriminator_h2\")(h)\n",
    "        h = LeakyReLU(0.2)(h)\n",
    "        y = Dense(1, name=\"discriminator_y\", activation=\"sigmoid\")(h)\n",
    "        return Model(z, y)\n",
    "    \n",
    "    def create_decoder(self):\n",
    "        \n",
    "        z = Input(shape=(self.dim[1],))\n",
    "\n",
    "        act = 'tanh'\n",
    "        decoder_h = Dense(self.dim[0], kernel_initializer='glorot_normal', activation=act)\n",
    "        decoder_mean = Dense(self.nb_words, activation='softmax')\n",
    "\n",
    "        h_decoded = decoder_h(z)\n",
    "        h_decoded = RepeatVector(self.max_len)(h_decoded)\n",
    "        h_decoded = Bidirectional(LSTM(self.dim[0], return_sequences=True, name='dec_lstm_1'))(h_decoded)\n",
    "        x_decoded_mean = TimeDistributed(decoder_mean, name='decoded_mean')(h_decoded)\n",
    "\n",
    "\n",
    "        return Model(z, x_decoded_mean, name=\"decoder\")\n",
    "    \n",
    "    def create_encoder(self):\n",
    "        \n",
    "        act = 'tanh'\n",
    "        x = Input(shape=(self.max_len,))\n",
    "        embed_layer = self.emb\n",
    "        bilstm = Bidirectional(LSTM(self.dim[0], name='lstm_1'))\n",
    "        hidden_layer1 = Dense(self.dim[0], kernel_initializer='glorot_normal', activation=act)\n",
    "        \n",
    "        h1 = embed_layer(x)\n",
    "        h1 = bilstm(h1)\n",
    "        h1 = hidden_layer1(h1)\n",
    "\n",
    "        self.z_mean = Dense(self.dim[1], kernel_initializer='glorot_normal')(h1)\n",
    "        self.z_log_var = Dense(self.dim[1], kernel_initializer='glorot_normal')(h1)\n",
    "\n",
    "        if self.comp_topk != None:\n",
    "            self.z_mean = KCompetitive(self.comp_topk, self.ctype)(self.z_mean)\n",
    "\n",
    "        z = Lambda(self.sampling, output_shape=(self.dim[1],))([self.z_mean, self.z_log_var])\n",
    "        \n",
    "        return Model(x, z, name=\"encoder\")\n",
    "\n",
    "\n",
    "\n",
    "    def vae_loss(self, x, x_decoded_mean):\n",
    "        # xent_loss =  self.max_len * K.sum(K.binary_crossentropy(x_decoded_mean, x), axis=-1)\n",
    "        x = K.flatten(x)\n",
    "        x_decoded_mean = K.flatten(x_decoded_mean)\n",
    "        xent_loss = self.max_len * objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "        kl_loss = - 0.5 * K.sum(1 + self.z_log_var - K.square(self.z_mean) - K.exp(self.z_log_var), axis=-1)\n",
    "\n",
    "        return xent_loss + kl_loss\n",
    "\n",
    "\n",
    "\n",
    "    def sampling(self, args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], self.dim[1]), mean=0.,\\\n",
    "                                  stddev=self.epsilon_std)\n",
    "\n",
    "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "    def initModel(self, sp, bpe_dict):\n",
    "        self.sp = sp\n",
    "        self.bpe_dict = bpe_dict\n",
    "\n",
    "    def batch_generator(self, reader, train_data, batch_size):\n",
    "        while True:\n",
    "            for df in reader:\n",
    "                \n",
    "                x = parse_texts_bpe(df.q.tolist(), self.sp, self.bpe_dict, self.max_len, True)\n",
    "                x_one_hot = to_categorical(x, self.nb_words)\n",
    "                x_one_hot = x_one_hot.reshape(batch_size, self.max_len, self.nb_words)\n",
    "                valid = np.ones(batch_size)\n",
    "                fake = np.zeros(batch_size)\n",
    "                yield x, [x_one_hot, valid, fake, x_one_hot, fake, valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_h1 (Dense)         (None, 512)               51712     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "generator_h2 (Dense)         (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "generator_x_flat (Dense)     (None, 784)               402192    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "generator_x (Reshape)        (None, 28, 28)            0         \n",
      "=================================================================\n",
      "Total params: 716,560\n",
      "Trainable params: 716,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x (InputLayer)                  (None, 28, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 784)          0           x[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_h1 (Dense)              (None, 512)          401920      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 512)          0           encoder_h1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder_h2 (Dense)              (None, 512)          262656      leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 512)          0           encoder_h2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder_mu (Dense)              (None, 100)          51300       leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_log_sigma_sq (Dense)    (None, 100)          51300       leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "merge_2 (Merge)                 (None, 100)          0           encoder_mu[0][0]                 \n",
      "                                                                 encoder_log_sigma_sq[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 767,176\n",
      "Trainable params: 767,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "discriminator_h1 (Dense)     (None, 512)               51712     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "discriminator_h2 (Dense)     (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "discriminator_y (Dense)      (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 314,881\n",
      "Trainable params: 314,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "x (InputLayer)               (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 100)               767176    \n",
      "_________________________________________________________________\n",
      "generator (Sequential)       (None, 28, 28)            716560    \n",
      "=================================================================\n",
      "Total params: 1,483,736\n",
      "Trainable params: 1,483,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# This line allows mpl to run with no DISPLAY defined\n",
    "mpl.use('Agg')\n",
    "\n",
    "from keras.layers import Dense, Reshape, Flatten, Input, merge\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras_adversarial.legacy import l1l2\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras_adversarial.image_grid_callback import ImageGridCallback\n",
    "\n",
    "from keras_adversarial import AdversarialModel, fix_names, n_choice\n",
    "from keras_adversarial import AdversarialOptimizerSimultaneous, normal_latent_sampling\n",
    "# from mnist_utils import mnist_data\n",
    "from keras.layers import LeakyReLU, Activation\n",
    "import os\n",
    "\n",
    "\n",
    "def model_generator(latent_dim, input_shape, hidden_dim=512, reg=lambda: l1l2(1e-7, 0)):\n",
    "    return Sequential([\n",
    "        Dense(hidden_dim, name=\"generator_h1\", input_dim=latent_dim, W_regularizer=reg()),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(hidden_dim, name=\"generator_h2\", W_regularizer=reg()),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(np.prod(input_shape), name=\"generator_x_flat\", W_regularizer=reg()),\n",
    "        Activation('sigmoid'),\n",
    "        Reshape(input_shape, name=\"generator_x\")],\n",
    "        name=\"generator\")\n",
    "\n",
    "\n",
    "def model_encoder(latent_dim, input_shape, hidden_dim=512, reg=lambda: l1l2(1e-7, 0)):\n",
    "    x = Input(input_shape, name=\"x\")\n",
    "    h = Flatten()(x)\n",
    "    h = Dense(hidden_dim, name=\"encoder_h1\", W_regularizer=reg())(h)\n",
    "    h = LeakyReLU(0.2)(h)\n",
    "    h = Dense(hidden_dim, name=\"encoder_h2\", W_regularizer=reg())(h)\n",
    "    h = LeakyReLU(0.2)(h)\n",
    "    mu = Dense(latent_dim, name=\"encoder_mu\", W_regularizer=reg())(h)\n",
    "    log_sigma_sq = Dense(latent_dim, name=\"encoder_log_sigma_sq\", W_regularizer=reg())(h)\n",
    "    z = merge([mu, log_sigma_sq], mode=lambda p: p[0] + K.random_normal(K.shape(p[0])) * K.exp(p[1] / 2),\n",
    "              output_shape=lambda p: p[0])\n",
    "    return Model(x, z, name=\"encoder\")\n",
    "\n",
    "\n",
    "def model_discriminator(latent_dim, output_dim=1, hidden_dim=512,\n",
    "                        reg=lambda: l1l2(1e-7, 1e-7)):\n",
    "\n",
    "    z = Input((latent_dim,))\n",
    "    h = z\n",
    "    h = Dense(hidden_dim, name=\"discriminator_h1\", W_regularizer=reg())(h)\n",
    "    h = LeakyReLU(0.2)(h)\n",
    "    h = Dense(hidden_dim, name=\"discriminator_h2\", W_regularizer=reg())(h)\n",
    "    h = LeakyReLU(0.2)(h)\n",
    "    y = Dense(output_dim, name=\"discriminator_y\", activation=\"sigmoid\", W_regularizer=reg())(h)\n",
    "    return Model(z, y)\n",
    "\n",
    "\n",
    "def example_aae(path, adversarial_optimizer):\n",
    "    # z \\in R^100\n",
    "    latent_dim = 100\n",
    "    # x \\in R^{28x28}\n",
    "    input_shape = (28, 28)\n",
    "\n",
    "    # generator (z -> x)\n",
    "    generator = model_generator(latent_dim, input_shape)\n",
    "    # encoder (x ->z)\n",
    "    encoder = model_encoder(latent_dim, input_shape)\n",
    "    # autoencoder (x -> x')\n",
    "    autoencoder = Model(encoder.inputs, generator(encoder(encoder.inputs)))\n",
    "    # discriminator (z -> y)\n",
    "    discriminator = model_discriminator(latent_dim)\n",
    "\n",
    "    # assemple AAE\n",
    "    x = encoder.inputs[0]\n",
    "    z = encoder(x)\n",
    "    xpred = generator(z)\n",
    "    zreal = normal_latent_sampling((latent_dim,))(x)\n",
    "    yreal = discriminator(zreal)\n",
    "    yfake = discriminator(z)\n",
    "    aae = Model(x, fix_names([xpred, yfake, yreal], [\"xpred\", \"yfake\", \"yreal\"]))\n",
    "\n",
    "    # print summary of models\n",
    "    generator.summary()\n",
    "    encoder.summary()\n",
    "    discriminator.summary()\n",
    "    autoencoder.summary()\n",
    "\n",
    "    # build adversarial model\n",
    "    generative_params = generator.trainable_weights + encoder.trainable_weights\n",
    "    model = AdversarialModel(base_model=aae,\n",
    "                             player_params=[generative_params, discriminator.trainable_weights],\n",
    "                             player_names=[\"generator\", \"discriminator\"])\n",
    "    model.adversarial_compile(adversarial_optimizer=adversarial_optimizer,\n",
    "                              player_optimizers=[Adam(1e-4, decay=1e-4), Adam(1e-3, decay=1e-4)],\n",
    "                              loss={\"yfake\": \"binary_crossentropy\", \"yreal\": \"binary_crossentropy\",\n",
    "                                    \"xpred\": \"mean_squared_error\"},\n",
    "                              player_compile_kwargs=[{\"loss_weights\": {\"yfake\": 1e-2, \"yreal\": 1e-2, \"xpred\": 1}}] * 2)\n",
    "\n",
    "#     # load mnist data\n",
    "#     xtrain, xtest = mnist_data()\n",
    "\n",
    "#     # callback for image grid of generated samples\n",
    "#     def generator_sampler():\n",
    "#         zsamples = np.random.normal(size=(10 * 10, latent_dim))\n",
    "#         return generator.predict(zsamples).reshape((10, 10, 28, 28))\n",
    "\n",
    "#     generator_cb = ImageGridCallback(os.path.join(path, \"generated-epoch-{:03d}.png\"), generator_sampler)\n",
    "\n",
    "#     # callback for image grid of autoencoded samples\n",
    "#     def autoencoder_sampler():\n",
    "#         xsamples = n_choice(xtest, 10)\n",
    "#         xrep = np.repeat(xsamples, 9, axis=0)\n",
    "#         xgen = autoencoder.predict(xrep).reshape((10, 9, 28, 28))\n",
    "#         xsamples = xsamples.reshape((10, 1, 28, 28))\n",
    "#         samples = np.concatenate((xsamples, xgen), axis=1)\n",
    "#         return samples\n",
    "\n",
    "#     autoencoder_cb = ImageGridCallback(os.path.join(path, \"autoencoded-epoch-{:03d}.png\"), autoencoder_sampler)\n",
    "\n",
    "#     # train network\n",
    "#     # generator, discriminator; pred, yfake, yreal\n",
    "#     n = xtrain.shape[0]\n",
    "#     y = [xtrain, np.ones((n, 1)), np.zeros((n, 1)), xtrain, np.zeros((n, 1)), np.ones((n, 1))]\n",
    "#     ntest = xtest.shape[0]\n",
    "#     ytest = [xtest, np.ones((ntest, 1)), np.zeros((ntest, 1)), xtest, np.zeros((ntest, 1)), np.ones((ntest, 1))]\n",
    "#     history = model.fit(x=xtrain, y=y, validation_data=(xtest, ytest), callbacks=[generator_cb, autoencoder_cb],\n",
    "#                         nb_epoch=100, batch_size=32)\n",
    "\n",
    "#     # save history\n",
    "#     df = pd.DataFrame(history.history)\n",
    "#     df.to_csv(os.path.join(path, \"history.csv\"))\n",
    "\n",
    "#     # save model\n",
    "#     encoder.save(os.path.join(path, \"encoder.h5\"))\n",
    "#     generator.save(os.path.join(path, \"generator.h5\"))\n",
    "#     discriminator.save(os.path.join(path, \"discriminator.h5\"))\n",
    "\n",
    "\n",
    "def main():\n",
    "    example_aae(\"output/aae\", AdversarialOptimizerSimultaneous())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
