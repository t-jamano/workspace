{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Models import *\n",
    "from Utils import *\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import sentencepiece as spm\n",
    "\n",
    "max_len = 15\n",
    "enablePadding = False\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('/work/data/bpe/en.wiki.bpe.op50000.model')\n",
    "bpe = KeyedVectors.load_word2vec_format(\"/work/data/bpe/en.wiki.bpe.op50000.d200.w2v.bin\", binary=True)\n",
    "bpe.index2word = [''] + bpe.index2word + ['<sos>'] + ['<eos>']  # add empty string \n",
    "nb_words = len(bpe.index2word)\n",
    "# word2index\n",
    "bpe_dict = {bpe.index2word[i]: i for i in range(len(bpe.index2word))}\n",
    "# construct embedding_matrix\n",
    "embedding_matrix = np.concatenate([np.zeros((1, bpe.vector_size)), bpe.vectors, np.zeros((2, bpe.vector_size))]) # add zero vector for empty string (i.e. used for padding)\n",
    "\n",
    "embedding_layer = Embedding(nb_words,\n",
    "                    embedding_matrix.shape[-1],\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_len,\n",
    "                    trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/data/t-mipha/agix/datasets/query_logs/CLICKED_QQ_MUL_2017-01-01_2017-06-10_r_train_ASCIIonly.txt\", nrows=1000000, sep=\"\\t\", header=None, names=['q', 'd', 'label', 'feature', 'null'])\n",
    "df = df.dropna()\n",
    "df.d = [i.split(\"<sep>\")[0] for i in df.d.tolist()]\n",
    "df.label = np.ones(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sts2015_df = pd.read_csv(\"/work/workspace/dataset-sts/data/sts/semeval-sts/all/2015.train.tsv\", sep=\"\\t\", header=None, error_bad_lines=False, names=[\"label\", \"q\", \"d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sts2015_df = pd.read_csv(\"/work/workspace/dataset-sts/data/sts/semeval-sts/all/2015.test.tsv\", sep=\"\\t\", names=[\"label\", \"q\", \"d\"],  header=None, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not a string\n",
      "not a string\n",
      "not a string\n",
      "not a string\n",
      "not a string\n",
      "not a string\n",
      "not a string\n"
     ]
    }
   ],
   "source": [
    "q_sts2015_df = parse_texts_bpe(sts2015_df.q.tolist(), sp, bpe_dict, max_len, enablePadding)\n",
    "d_sts2015_df = parse_texts_bpe(sts2015_df.d.tolist(), sp, bpe_dict, max_len, enablePadding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 328 ms, sys: 28 ms, total: 356 ms\n",
      "Wall time: 349 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"/work/data/train_data/30M_QD_lower2.txt\", nrows=100000, usecols=[0,1,2], names=[\"label\",\"q\", \"d\"], sep=\"\\t\", header=None, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = df[df.label == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.14 s, sys: 128 ms, total: 9.27 s\n",
      "Wall time: 9.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "enablePadding = False\n",
    "q_df = parse_texts_bpe(df.q.tolist(), sp, bpe_dict, max_len, enablePadding, \"post\")\n",
    "d_df = parse_texts_bpe(df.d.tolist(), sp, bpe_dict, max_len, enablePadding, \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addTags(x, bpe_dict, max_len):\n",
    "    dec_input = np.copy(x)\n",
    "    dec_output = np.copy(x)\n",
    "    for i in range(len(x)):\n",
    "        dec_input[i] = [bpe_dict['<sos>']] + dec_input[i] + [bpe_dict['<eos>']]\n",
    "        dec_output[i] = dec_output[i] + [bpe_dict['<eos>']]\n",
    "\n",
    "    return pad_sequences(dec_input, maxlen=max_len, padding=\"post\"), pad_sequences(dec_output, maxlen=max_len, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_dec_inputs, q_dec_outputs = addTags(q_df, bpe_dict, max_len)\n",
    "d_dec_inputs, d_dec_outputs = addTags(d_df, bpe_dict, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enablePadding = True\n",
    "q_df = parse_texts_bpe(df.q.tolist(), sp, bpe_dict, max_len, enablePadding, \"post\")\n",
    "d_df = parse_texts_bpe(df.d.tolist(), sp, bpe_dict, max_len, enablePadding, \"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"/work/data/train_data/100K_QD_ml15.q.npy\", q_df)\n",
    "np.save(\"/work/data/train_data/100K_QD_ml15.d.npy\", d_df)\n",
    "np.save(\"/work/data/train_data/100K_QD_ml15.label.npy\", df.label.values)\n",
    "\n",
    "np.save(\"/work/data/train_data/100K_QD_ml15.q.di.npy\", q_dec_inputs)\n",
    "np.save(\"/work/data/train_data/100K_QD_ml15.d.di.npy\", d_dec_inputs)\n",
    "\n",
    "np.save(\"/work/data/train_data/100K_QD_ml15.q.do.npy\", q_dec_outputs)\n",
    "np.save(\"/work/data/train_data/100K_QD_ml15.d.do.npy\", d_dec_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dec_q_train = pad_sequences(pad_sequences(q_df_, maxlen=max_len+1, value=bpe_dict['<sos>']), maxlen=max_len, truncating=\"post\")\n",
    "# dec_d_train = pad_sequences(pad_sequences(d_df_, maxlen=max_len+1, value=bpe_dict['<sos>']), maxlen=max_len, truncating=\"post\")\n",
    "\n",
    "# np.save(\"/work/data/train_data/30M_QD_ml15.q_.<sos>.npy\", dec_q_train)\n",
    "# np.save(\"/work/data/train_data/30M_QD_ml15.d_.<sos>.npy\", dec_d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save(\"/work/data/train_data/30M_QD_ml15.q.npy\", q_df)\n",
    "# np.save(\"/work/data/train_data/30M_QD_ml15.d.npy\", d_df)\n",
    "# np.save(\"/work/data/train_data/30M_QD_ml15.label.npy\", df.label.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save(\"/work/data/train_data/30M_QD_ml15.q_.npy\", q_df_)\n",
    "# np.save(\"/work/data/train_data/30M_QD_ml15.d_.npy\", d_df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_df = np.load(\"/work/data/train_data/30M_QD_ml15.q_.<sos>.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos>\n",
      "▁facebook\n",
      "▁log\n",
      "▁in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_df[0]\n",
    "for i in q_df[0]:\n",
    "    print(bpe.index2word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50510,  7461,  4212, ...,     0,     0,     0],\n",
       "       [50510,  3802, 34943, ...,     0,     0,     0],\n",
       "       [50510,  1850,     8, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [50510,  6824,   106, ...,     0,     0,     0],\n",
       "       [50510,  6455, 11146, ...,     0,     0,     0],\n",
       "       [50510, 14651,  1451, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  7461,  4212,     5],\n",
       "       [    0,     0,     0, ..., 43852,  2966,  2936],\n",
       "       [    0,     0,     0, ...,  1365,    89,  6772],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  9597,  1136,  1523],\n",
       "       [    0,     0,     0, ...,  6455, 11146, 13095],\n",
       "       [    0,     0,     0, ...,   978,  1440,  1584]], dtype=int32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos>'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.index2word[50510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 19898: expected 6 fields, saw 8\\nSkipping line 20620: expected 6 fields, saw 8\\nSkipping line 38039: expected 6 fields, saw 8\\n'\n"
     ]
    }
   ],
   "source": [
    "df_may, qrel_may = get_test_data(\"MayFlower\", \"/work/\")\n",
    "df_june, qrel_june = get_test_data(\"JuneFlower\", \"/work/\")\n",
    "df_july, qrel_july = get_test_data(\"JulyFlower\", \"/work/\")\n",
    "\n",
    "enablePadding = False\n",
    "\n",
    "q_may = parse_texts_bpe(df_may.q.tolist(), sp, bpe_dict, max_len, enablePadding)\n",
    "d_may = parse_texts_bpe(df_may.d.tolist(), sp, bpe_dict, max_len, enablePadding)\n",
    "\n",
    "q_june = parse_texts_bpe(df_june.q.tolist(), sp, bpe_dict, max_len, enablePadding)\n",
    "d_june = parse_texts_bpe(df_june.d.tolist(), sp, bpe_dict, max_len, enablePadding)\n",
    "\n",
    "q_july = parse_texts_bpe(df_july.q.tolist(), sp, bpe_dict, max_len, enablePadding)\n",
    "d_july = parse_texts_bpe(df_july.d.tolist(), sp, bpe_dict, max_len, enablePadding)\n",
    "\n",
    "q_july_ = parse_texts_bpe(df_july.q.tolist(), sp, bpe_dict, max_len, enablePadding, \"post\")\n",
    "d_july_ = parse_texts_bpe(df_july.d.tolist(), sp, bpe_dict, max_len, enablePadding, \"post\")\n",
    "\n",
    "test_set = [[q_may, d_may, qrel_may, df_may, \"MayFlower\"], [q_june, d_june, qrel_june, df_june, \"JuneFlower\"], [q_july, d_july, qrel_july, df_july, \"JulyFlower\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁thyroid'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.index2word[25942]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_test_tokens = set([])\n",
    "test_tokens = []\n",
    "for i in [q_may, d_may, q_june, d_june, q_july, d_july]:\n",
    "    for j in i:\n",
    "        for k in j:\n",
    "            set_test_tokens.add(k)\n",
    "            test_tokens.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndQwHSVLHcJAkdQwHSVLHcJAkdf4/uU9W52Q6IEQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f02910ab400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "word_list = test_tokens\n",
    "\n",
    "counts = Counter(word_list)\n",
    "\n",
    "labels, values = zip(*counts.items())\n",
    "\n",
    "# sort your values in descending order\n",
    "indSort = np.argsort(values)[::-1]\n",
    "\n",
    "# rearrange your data\n",
    "labels = np.array(labels)[indSort]\n",
    "values = np.array(values)[indSort]\n",
    "\n",
    "indexes = np.arange(len(labels))\n",
    "\n",
    "bar_width = 0.35\n",
    "\n",
    "plt.bar(indexes, values)\n",
    "\n",
    "# add labels\n",
    "plt.xticks(indexes + bar_width, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  168,     8, 50509,     1,   594,     5,     4,     7,   366,\n",
       "          11,    14,    15,   679,   356,     3,     6,  5977,    13,\n",
       "         469,    93,   141,   315,   759,    18,   726,    28,    17,\n",
       "        1686,  1208,    59,   418,    26,    34,    65,  2365, 47369,\n",
       "           2,   360,    55,    31,   156,    86,  3213,  1201,   249,\n",
       "        2849,  3936,   107,   220,   460,    24,   136,    12,  2573,\n",
       "          51,    77,   290,  1083,  2779,   551,  1566,   250, 28624,\n",
       "          72,  2043,    84,  1486,    44, 49350,   212,    38,  3880,\n",
       "          92,  2513,   218,   562,  4212,    35,   374,  1546,   197,\n",
       "         192,    88,   196,    16,   180,  2001,   152,    98,   235,\n",
       "         166,   371,    89,  3473,   184,  2522,  2782,   465,   549,\n",
       "        1380, 16375,    49,   830, 12203,     9,    70,    46,    22,\n",
       "         274,  1175,   530,  4238,   137,   659,  1440,   163,   159,\n",
       "         330,   965,   135,   643,   146,   367,   108,   814,   272,\n",
       "        6675,   306,    19,    42,   370,   181,   727,   394,   201,\n",
       "          85,   359,   586,  2472,    99,   406,   167,   284,   580,\n",
       "         341,  1584,   317,  2048,   219,  6509,   504,   634,  1022,\n",
       "         702,   270,   262,  3355,   276,   472,   519,   271,   744,\n",
       "         176,   240,   714,   333,  1211,   413,   243,   273,   242,\n",
       "          87,  7244,   841,    54,   292,  7461,   404,   743,   123,\n",
       "        6557,   267,    53,   412,   301,   332,   385,   172,  1841,\n",
       "         254,   140,   380,   597, 19456,  1591,  1680,  2878,   241,\n",
       "          75,   343,   355,   966,   784,    80,  4975,   436,   281,\n",
       "         251,   477,   450, 18075,   857,   596,    40, 49075,   447,\n",
       "       10947,  3525,  3179,  4971,  4658,   431,  1222,  2111,   307,\n",
       "         309,   847,   362,  3523,  5078,  1723,   238,  2444,  1862,\n",
       "        4048,  6207,  3338,  3354,  4072,   564,    63,  1639,   182,\n",
       "         650,  1927,  1789,  1160,   345,   127,   313,   552, 12147,\n",
       "         769,   456,   247,   633,  1067,  3405,  1844,   129,  1912,\n",
       "         154,   335,   120,  1395, 24453,  1826,  8108,  3890,  4102,\n",
       "        3207,  1694,   300,   398,   383,  1996,  5049,  2679,  1487,\n",
       "       10136,   625,  2986,    21,   571,   578,   105,   101,   245,\n",
       "         403,  3171,   390,  4330,   954,   106,   320,  1288,   969,\n",
       "         179,  4321,   751,  1136,   850,   428,  5257,  4160,   416,\n",
       "        1181,  3783,  1685,   817,   210,  2284,  2158,  9277,   568,\n",
       "        3008,  1313,  1055,   547,  3169,   126,  1489,  2349,  3043,\n",
       "        1522,  4530,  1094,  5890,   207,  2104,   143,  6652,   288,\n",
       "        2251,  2521,   321,   760,   765,   349,   392,   415,   104,\n",
       "        3010,   505,  9133, 10640,   637,   231,  1383,   546,   735,\n",
       "        5421, 19956, 15594,   766,  1569,   205,   678,  4970,  1992,\n",
       "        7247,  1759,   193,   350,  1197,  2570,  1095,  1195,  1728,\n",
       "         297,   130,  1333,  1305,   523,  2473,   379,   162, 25880,\n",
       "        1037,  1296,   720,  1485,  8061,  2572,   158,   294, 14419,\n",
       "        1177,  3597,  1664,  1876,  7297,  2185,  3967,  6392,   198,\n",
       "         526,   337,   336,  1171,   487,   217,   363,  6283,   514,\n",
       "         216,  2794,   323,   524,    32, 18544,   405,  1124,   151,\n",
       "         566,  5243,  1269,   701,  2962,   509,  1701,    90,  5710,\n",
       "         503,   411, 23253,  1493,   653, 32566,  4105, 26307,  3380,\n",
       "        1752,  1268, 15337,   402,   112,   111,  1217,   316,   451,\n",
       "         747,  3660,  6955,   295,   821,  3725,   606,    71,   252,\n",
       "        3413,  4563,   395,  6144,  5363,  1278,    56,  4704,   144,\n",
       "        5077,  2049,   134,  1120,   616,  7165,   325,   185,  1843,\n",
       "        1112,  3230,  5203,  2624,   620,  1373,    10,   358,  2936,\n",
       "        9220,  3844,  1327,  1060,   485,   622,  3133, 36421,  1311,\n",
       "         818,   443,   889,   782,   877,    83,  1621,   500,  1846,\n",
       "        1194,  1285,  3762,   754,  1034,  1107,   626,  1340,  1907,\n",
       "         531,   228,   440,  6458,   779,   334,   397,   518,   352,\n",
       "        1452,  7115,   444,   439,  2160,  1622,   226,  3071,   570,\n",
       "        3122,   174,  3731,  1365,  1657,  1577,  1152,  4124,  4343,\n",
       "         970,  1036,   314,   389,   981,  1543,   308,   602,   421,\n",
       "        2419,  2945,   990,  2811,   324,   277,  1344,  7683,  3055,\n",
       "          23,   266,   457,    76,   346,  4733,  5714,  1062,   278,\n",
       "        5637,   894,   806,   983, 12021,   484,  1872,   629,  2412,\n",
       "         697,  1256, 20001,  1463,   963,  2985,  1098,   740,  1359,\n",
       "        8691,  1048,   601, 10105,   774,  5245,  1343,  7317,  5089,\n",
       "       11191,   964,  1985,   691,  3556,   434,  8070,  1982,   497,\n",
       "         856, 15875,  4172,   544, 14656,   521,   563,   866,   574,\n",
       "         328,   977,  1025,   554,  3023,   381,  1015,  2132,  2451,\n",
       "        1716, 13745, 21430,  2593,   489,  2927,  1183, 12999,  9356,\n",
       "        5870,   435,  2277,  8999,    74,   758, 14709,  3373,   699,\n",
       "       16207,  5255,   794,   976,  1579,  3277,  2415,   905,  1354,\n",
       "        4836,  3184,   804, 26665,  1179,   761,  1824,  9499,  2503,\n",
       "         646,  9386,  2917,  2546,  2076,   902,  2223,  1367,  9831,\n",
       "        1220,   225,   396,  1896,  4661,   922,  1592,  3757, 27263,\n",
       "         209,  4121,   338,  5095,   467,  7128,  1698,    37,   222,\n",
       "         482,   848,  4034, 20592,   373,   502,   588,  8168,  7076,\n",
       "         842,  1899,  1010,   607,   861,  1783,  1443,  2516,   236,\n",
       "        1385,  1306,  2843,  1082,  1641,  4776,  4402,   801,   329,\n",
       "        1118,   675,  3119,   955,  2441,   833,   592,  2844,  1464,\n",
       "         473,  1850,  1575,   807,  3554,   698,  3987,  2792,  1797,\n",
       "        1291,  1963,  1049,  2314,  1253, 16072, 10412,    27,   400,\n",
       "        7045,  1594,   354,  5141,  5914,   543,  1974,   221,  1358,\n",
       "        1030,  8992,  4623,  1750,  1099,   153,  7835,   322,  3077,\n",
       "        3621, 14324, 25148,  1934,  2537,  7535,  3775,  8467,    73,\n",
       "         187,   169,  5174,   690,  2578,   881, 12936,  4522,  6119,\n",
       "        1601, 31764,   357,   986,  6376,  8309,  1524,  5430,   479,\n",
       "        3007,   556,  4035,  1122,   777,  5738,  7327,   919, 18509,\n",
       "        8715, 11649, 17613,   628,   116,   125,  3847,  4120,  5673,\n",
       "       18801,  3314,   490, 24676,  1406,  1607,  1665,  1732,  5603,\n",
       "        1029,   704,  4827,  3390,  1182, 12878, 18165,   100,  8540,\n",
       "       11025,  1801,   446,  1364,  4235,  2726,  3188,  7728, 12934,\n",
       "       26685,  8089,  2332,  3287, 49963,  1064,   175,  1103,  1555,\n",
       "        1230,  1398,  1534,  1167,   849,  1163,   604,  1785,  1174,\n",
       "         655,  3337,   560,  8397,  1942,  4387,  5533,  2183,   148,\n",
       "        5337,  5003,   786,   719,  1545,  1206,  2523,  1695,  2781,\n",
       "        8140,  4306,   537,  1316,   384,    57,  3553,  3421,  1137,\n",
       "        9700,  1488,  5986,  1277,  2192,  1647, 14451,  4819,  7681,\n",
       "        1925,   685,  5380,  3443,   753, 28943,  2348,  3019,  1499,\n",
       "        6772,  3331,  3519,  1712,  1962, 12016,   573,  5040,  1320,\n",
       "        8731,  6460,  8777,  1047,  5128,  7756,  1563,  3085,   688,\n",
       "         729,  2887,    43,   255, 26277,  2294,  1337,  2130, 10457,\n",
       "        1436,  1812, 11617,  2275,   160,   871,   348,  3819,   683,\n",
       "        2538,  8364,  4320,   862,  1729,   662,   191,  2818,  8917,\n",
       "         987,   206,  1957, 12816,  1212,    48,  2152,   656,   286,\n",
       "        2070,  4274, 16943, 21214,  4369,  1551,  1088,  2909,  2097,\n",
       "         189,  3495,   979, 15465,  2157,  1368,   303,  2476,   615,\n",
       "        6743,  1674,  4242, 25465,  7647, 24900, 20804,  1552,  4064,\n",
       "        2920,  1184,  1710,  2208,   897,  1315,  6963,  5223,  3930,\n",
       "       13287,   888,  2934,  3852,  5106,  4682,  8771, 25491,   733,\n",
       "        5784,  2174,  9923,  2666,  2082, 12991,   282,  9791, 17000,\n",
       "        2236, 12730,  2588,  1033,  1668,  1930,  8607,  5796,  4907,\n",
       "        7052])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16748, 16216, 15207, ...,    18,    18,    18])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16748,\n",
       " 16216,\n",
       " 15207,\n",
       " 12632,\n",
       " 12559,\n",
       " 12016,\n",
       " 11031,\n",
       " 10157,\n",
       " 9487,\n",
       " 8855,\n",
       " 7127,\n",
       " 4618,\n",
       " 4028,\n",
       " 3748,\n",
       " 3531,\n",
       " 3308,\n",
       " 3196,\n",
       " 3089,\n",
       " 2914,\n",
       " 2476,\n",
       " 2202,\n",
       " 2052,\n",
       " 1976,\n",
       " 1947,\n",
       " 1910,\n",
       " 1891,\n",
       " 1730,\n",
       " 1541,\n",
       " 1502,\n",
       " 1488,\n",
       " 1453,\n",
       " 1432,\n",
       " 1422,\n",
       " 1364,\n",
       " 1287,\n",
       " 1280,\n",
       " 1275,\n",
       " 1235,\n",
       " 1208,\n",
       " 1173,\n",
       " 1163,\n",
       " 1157,\n",
       " 1125,\n",
       " 1091,\n",
       " 1087,\n",
       " 1082,\n",
       " 1074,\n",
       " 1056,\n",
       " 1036,\n",
       " 1028,\n",
       " 1012,\n",
       " 960,\n",
       " 937,\n",
       " 900,\n",
       " 886,\n",
       " 884,\n",
       " 865,\n",
       " 851,\n",
       " 849,\n",
       " 846,\n",
       " 837,\n",
       " 829,\n",
       " 803,\n",
       " 794,\n",
       " 785,\n",
       " 778,\n",
       " 764,\n",
       " 747,\n",
       " 728,\n",
       " 726,\n",
       " 725,\n",
       " 692,\n",
       " 677,\n",
       " 671,\n",
       " 641,\n",
       " 634,\n",
       " 619,\n",
       " 619,\n",
       " 617,\n",
       " 611,\n",
       " 608,\n",
       " 607,\n",
       " 603,\n",
       " 602,\n",
       " 600,\n",
       " 597,\n",
       " 592,\n",
       " 590,\n",
       " 581,\n",
       " 572,\n",
       " 570,\n",
       " 565,\n",
       " 556,\n",
       " 551,\n",
       " 549,\n",
       " 548,\n",
       " 546,\n",
       " 540,\n",
       " 540,\n",
       " 536,\n",
       " 529,\n",
       " 526,\n",
       " 522,\n",
       " 521,\n",
       " 520,\n",
       " 516,\n",
       " 510,\n",
       " 510,\n",
       " 508,\n",
       " 508,\n",
       " 507,\n",
       " 503,\n",
       " 500,\n",
       " 496,\n",
       " 490,\n",
       " 488,\n",
       " 488,\n",
       " 488,\n",
       " 485,\n",
       " 485,\n",
       " 482,\n",
       " 480,\n",
       " 479,\n",
       " 478,\n",
       " 477,\n",
       " 475,\n",
       " 472,\n",
       " 472,\n",
       " 469,\n",
       " 467,\n",
       " 466,\n",
       " 463,\n",
       " 463,\n",
       " 462,\n",
       " 460,\n",
       " 457,\n",
       " 456,\n",
       " 456,\n",
       " 456,\n",
       " 448,\n",
       " 446,\n",
       " 440,\n",
       " 436,\n",
       " 434,\n",
       " 434,\n",
       " 431,\n",
       " 431,\n",
       " 430,\n",
       " 429,\n",
       " 429,\n",
       " 425,\n",
       " 425,\n",
       " 424,\n",
       " 422,\n",
       " 419,\n",
       " 418,\n",
       " 414,\n",
       " 413,\n",
       " 411,\n",
       " 410,\n",
       " 408,\n",
       " 408,\n",
       " 406,\n",
       " 405,\n",
       " 405,\n",
       " 405,\n",
       " 404,\n",
       " 404,\n",
       " 403,\n",
       " 403,\n",
       " 400,\n",
       " 396,\n",
       " 396,\n",
       " 394,\n",
       " 392,\n",
       " 390,\n",
       " 387,\n",
       " 380,\n",
       " 378,\n",
       " 377,\n",
       " 377,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 374,\n",
       " 373,\n",
       " 373,\n",
       " 372,\n",
       " 372,\n",
       " 370,\n",
       " 368,\n",
       " 368,\n",
       " 367,\n",
       " 367,\n",
       " 366,\n",
       " 365,\n",
       " 365,\n",
       " 364,\n",
       " 364,\n",
       " 364,\n",
       " 361,\n",
       " 361,\n",
       " 360,\n",
       " 359,\n",
       " 359,\n",
       " 358,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 352,\n",
       " 352,\n",
       " 348,\n",
       " 346,\n",
       " 345,\n",
       " 344,\n",
       " 344,\n",
       " 343,\n",
       " 342,\n",
       " 341,\n",
       " 341,\n",
       " 341,\n",
       " 339,\n",
       " 338,\n",
       " 336,\n",
       " 335,\n",
       " 334,\n",
       " 333,\n",
       " 333,\n",
       " 333,\n",
       " 333,\n",
       " 330,\n",
       " 328,\n",
       " 327,\n",
       " 322,\n",
       " 321,\n",
       " 321,\n",
       " 321,\n",
       " 321,\n",
       " 320,\n",
       " 318,\n",
       " 316,\n",
       " 316,\n",
       " 316,\n",
       " 313,\n",
       " 310,\n",
       " 310,\n",
       " 310,\n",
       " 307,\n",
       " 306,\n",
       " 305,\n",
       " 304,\n",
       " 303,\n",
       " 302,\n",
       " 301,\n",
       " 300,\n",
       " 300,\n",
       " 299,\n",
       " 298,\n",
       " 297,\n",
       " 297,\n",
       " 297,\n",
       " 296,\n",
       " 296,\n",
       " 295,\n",
       " 295,\n",
       " 293,\n",
       " 293,\n",
       " 293,\n",
       " 292,\n",
       " 290,\n",
       " 290,\n",
       " 288,\n",
       " 287,\n",
       " 285,\n",
       " 285,\n",
       " 285,\n",
       " 285,\n",
       " 284,\n",
       " 284,\n",
       " 283,\n",
       " 283,\n",
       " 282,\n",
       " 281,\n",
       " 281,\n",
       " 281,\n",
       " 280,\n",
       " 279,\n",
       " 279,\n",
       " 278,\n",
       " 278,\n",
       " 277,\n",
       " 276,\n",
       " 275,\n",
       " 274,\n",
       " 273,\n",
       " 271,\n",
       " 270,\n",
       " 269,\n",
       " 269,\n",
       " 268,\n",
       " 268,\n",
       " 267,\n",
       " 267,\n",
       " 265,\n",
       " 264,\n",
       " 264,\n",
       " 264,\n",
       " 263,\n",
       " 263,\n",
       " 260,\n",
       " 259,\n",
       " 258,\n",
       " 256,\n",
       " 255,\n",
       " 255,\n",
       " 254,\n",
       " 254,\n",
       " 254,\n",
       " 253,\n",
       " 253,\n",
       " 252,\n",
       " 252,\n",
       " 252,\n",
       " 251,\n",
       " 250,\n",
       " 250,\n",
       " 250,\n",
       " 249,\n",
       " 249,\n",
       " 247,\n",
       " 247,\n",
       " 247,\n",
       " 245,\n",
       " 245,\n",
       " 245,\n",
       " 244,\n",
       " 244,\n",
       " 243,\n",
       " 242,\n",
       " 242,\n",
       " 242,\n",
       " 242,\n",
       " 241,\n",
       " 241,\n",
       " 240,\n",
       " 240,\n",
       " 239,\n",
       " 239,\n",
       " 238,\n",
       " 238,\n",
       " 237,\n",
       " 236,\n",
       " 236,\n",
       " 236,\n",
       " 236,\n",
       " 236,\n",
       " 235,\n",
       " 235,\n",
       " 235,\n",
       " 235,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 231,\n",
       " 231,\n",
       " 231,\n",
       " 231,\n",
       " 230,\n",
       " 230,\n",
       " 229,\n",
       " 229,\n",
       " 229,\n",
       " 229,\n",
       " 229,\n",
       " 228,\n",
       " 228,\n",
       " 228,\n",
       " 228,\n",
       " 227,\n",
       " 226,\n",
       " 226,\n",
       " 225,\n",
       " 225,\n",
       " 225,\n",
       " 224,\n",
       " 223,\n",
       " 219,\n",
       " 219,\n",
       " 219,\n",
       " 218,\n",
       " 218,\n",
       " 218,\n",
       " 217,\n",
       " 217,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 215,\n",
       " 214,\n",
       " 214,\n",
       " 214,\n",
       " 213,\n",
       " 213,\n",
       " 213,\n",
       " 213,\n",
       " 213,\n",
       " 212,\n",
       " 212,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 210,\n",
       " 209,\n",
       " 209,\n",
       " 209,\n",
       " 208,\n",
       " 208,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 205,\n",
       " 204,\n",
       " 204,\n",
       " 203,\n",
       " 203,\n",
       " 202,\n",
       " 202,\n",
       " 202,\n",
       " 202,\n",
       " 202,\n",
       " 201,\n",
       " 201,\n",
       " 200,\n",
       " 200,\n",
       " 199,\n",
       " 199,\n",
       " 198,\n",
       " 198,\n",
       " 198,\n",
       " 198,\n",
       " 198,\n",
       " 197,\n",
       " 196,\n",
       " 196,\n",
       " 196,\n",
       " 196,\n",
       " 196,\n",
       " 195,\n",
       " 194,\n",
       " 194,\n",
       " 194,\n",
       " 194,\n",
       " 193,\n",
       " 193,\n",
       " 193,\n",
       " 192,\n",
       " 192,\n",
       " 192,\n",
       " 192,\n",
       " 192,\n",
       " 191,\n",
       " 191,\n",
       " 191,\n",
       " 191,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 190,\n",
       " 189,\n",
       " 189,\n",
       " 189,\n",
       " 188,\n",
       " 187,\n",
       " 186,\n",
       " 186,\n",
       " 186,\n",
       " 185,\n",
       " 185,\n",
       " 185,\n",
       " 185,\n",
       " 185,\n",
       " 184,\n",
       " 184,\n",
       " 184,\n",
       " 184,\n",
       " 183,\n",
       " 182,\n",
       " 182,\n",
       " 182,\n",
       " 181,\n",
       " 181,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 179,\n",
       " 179,\n",
       " 178,\n",
       " 178,\n",
       " 177,\n",
       " 177,\n",
       " 177,\n",
       " 177,\n",
       " 177,\n",
       " 176,\n",
       " 176,\n",
       " 176,\n",
       " 175,\n",
       " 175,\n",
       " 175,\n",
       " 175,\n",
       " 175,\n",
       " 174,\n",
       " 174,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 172,\n",
       " 172,\n",
       " 172,\n",
       " 172,\n",
       " 172,\n",
       " 172,\n",
       " 172,\n",
       " 172,\n",
       " 172,\n",
       " 171,\n",
       " 171,\n",
       " 171,\n",
       " 171,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 170,\n",
       " 169,\n",
       " 169,\n",
       " 168,\n",
       " 168,\n",
       " 168,\n",
       " 168,\n",
       " 168,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 166,\n",
       " 166,\n",
       " 166,\n",
       " 166,\n",
       " 166,\n",
       " 166,\n",
       " 166,\n",
       " 166,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 164,\n",
       " 164,\n",
       " 164,\n",
       " 163,\n",
       " 163,\n",
       " 163,\n",
       " 163,\n",
       " 162,\n",
       " 162,\n",
       " 162,\n",
       " 162,\n",
       " 161,\n",
       " 161,\n",
       " 161,\n",
       " 161,\n",
       " 161,\n",
       " 161,\n",
       " 161,\n",
       " 161,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 160,\n",
       " 159,\n",
       " 159,\n",
       " 159,\n",
       " 159,\n",
       " 159,\n",
       " 159,\n",
       " 159,\n",
       " 159,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 157,\n",
       " 157,\n",
       " 157,\n",
       " 157,\n",
       " 157,\n",
       " 157,\n",
       " 156,\n",
       " 156,\n",
       " 156,\n",
       " 155,\n",
       " 155,\n",
       " 154,\n",
       " 154,\n",
       " 154,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 152,\n",
       " 152,\n",
       " 152,\n",
       " 151,\n",
       " 151,\n",
       " 151,\n",
       " 151,\n",
       " 151,\n",
       " 151,\n",
       " 151,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 149,\n",
       " 149,\n",
       " 149,\n",
       " 149,\n",
       " 149,\n",
       " 148,\n",
       " 148,\n",
       " 148,\n",
       " 148,\n",
       " 148,\n",
       " 148,\n",
       " 148,\n",
       " 148,\n",
       " 147,\n",
       " 147,\n",
       " 147,\n",
       " 147,\n",
       " 147,\n",
       " 147,\n",
       " 146,\n",
       " 146,\n",
       " 146,\n",
       " 146,\n",
       " 145,\n",
       " 145,\n",
       " 145,\n",
       " 145,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 143,\n",
       " 143,\n",
       " 143,\n",
       " 143,\n",
       " 143,\n",
       " 143,\n",
       " 143,\n",
       " 143,\n",
       " 143,\n",
       " 142,\n",
       " 142,\n",
       " 142,\n",
       " 142,\n",
       " 142,\n",
       " 142,\n",
       " 141,\n",
       " 141,\n",
       " 141,\n",
       " 141,\n",
       " 141,\n",
       " 141,\n",
       " 141,\n",
       " 141,\n",
       " 141,\n",
       " 141,\n",
       " 141,\n",
       " 141,\n",
       " 141,\n",
       " 141,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 139,\n",
       " 139,\n",
       " 139,\n",
       " 139,\n",
       " 139,\n",
       " 138,\n",
       " 138,\n",
       " 138,\n",
       " 138,\n",
       " 138,\n",
       " 138,\n",
       " 138,\n",
       " 138,\n",
       " 138,\n",
       " 137,\n",
       " 137,\n",
       " 137,\n",
       " 137,\n",
       " 137,\n",
       " 137,\n",
       " 137,\n",
       " 137,\n",
       " 137,\n",
       " 137,\n",
       " 137,\n",
       " 136,\n",
       " 136,\n",
       " 136,\n",
       " 136,\n",
       " 136,\n",
       " 136,\n",
       " 136,\n",
       " 136,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 134,\n",
       " 134,\n",
       " 134,\n",
       " 134,\n",
       " 134,\n",
       " 133,\n",
       " 133,\n",
       " 133,\n",
       " 133,\n",
       " 133,\n",
       " 133,\n",
       " 133,\n",
       " 132,\n",
       " 132,\n",
       " 132,\n",
       " 132,\n",
       " 132,\n",
       " 132,\n",
       " 132,\n",
       " 132,\n",
       " 132,\n",
       " 132,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 127,\n",
       " 127,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 125,\n",
       " 125,\n",
       " 125,\n",
       " 125,\n",
       " 125,\n",
       " 125,\n",
       " 125,\n",
       " 125,\n",
       " 125,\n",
       " 125,\n",
       " 125,\n",
       " 124,\n",
       " 124,\n",
       " 124,\n",
       " 124,\n",
       " 124,\n",
       " 124,\n",
       " 124,\n",
       " 124,\n",
       " 124,\n",
       " 123,\n",
       " 123,\n",
       " 123,\n",
       " 123,\n",
       " 123,\n",
       " 123,\n",
       " 123,\n",
       " 122,\n",
       " 122,\n",
       " 122,\n",
       " 122,\n",
       " 122,\n",
       " 122,\n",
       " 121,\n",
       " 121,\n",
       " 121,\n",
       " 121,\n",
       " 121,\n",
       " 121,\n",
       " 121,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 120,\n",
       " 119,\n",
       " 119,\n",
       " 119,\n",
       " 119,\n",
       " 119,\n",
       " 119,\n",
       " 118,\n",
       " 118,\n",
       " 118,\n",
       " 118,\n",
       " 118,\n",
       " 118,\n",
       " 118,\n",
       " 118,\n",
       " 117,\n",
       " 117,\n",
       " 117,\n",
       " 117,\n",
       " 117,\n",
       " 117,\n",
       " 117,\n",
       " 116,\n",
       " 116,\n",
       " 116,\n",
       " 116,\n",
       " 116,\n",
       " 116,\n",
       " 116,\n",
       " 116,\n",
       " 115,\n",
       " 115,\n",
       " 115,\n",
       " 115,\n",
       " 115,\n",
       " 115,\n",
       " 115,\n",
       " 115,\n",
       " 115,\n",
       " 115,\n",
       " 115,\n",
       " 114,\n",
       " 114,\n",
       " 114,\n",
       " 114,\n",
       " 114,\n",
       " 114,\n",
       " 114,\n",
       " 114,\n",
       " 114,\n",
       " 113,\n",
       " 113,\n",
       " 113,\n",
       " 113,\n",
       " 113,\n",
       " 113,\n",
       " 113,\n",
       " 113,\n",
       " 113,\n",
       " 113,\n",
       " 112,\n",
       " 112,\n",
       " 112,\n",
       " 112,\n",
       " 112,\n",
       " 112,\n",
       " 112,\n",
       " 112,\n",
       " 112,\n",
       " 112,\n",
       " 112,\n",
       " 112,\n",
       " 112,\n",
       " 112,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 109,\n",
       " 109,\n",
       " 109,\n",
       " 109,\n",
       " 109,\n",
       " 109,\n",
       " 109,\n",
       " 109,\n",
       " 109,\n",
       " 109,\n",
       " 108,\n",
       " 108,\n",
       " 108,\n",
       " 108,\n",
       " 108,\n",
       " 108,\n",
       " 108,\n",
       " 108,\n",
       " 107,\n",
       " 107,\n",
       " 107,\n",
       " 107,\n",
       " 107,\n",
       " 107,\n",
       " 107,\n",
       " ...]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.index2word[50509]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-4343a3c47211>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'q_df' is not defined"
     ]
    }
   ],
   "source": [
    "q_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.96 s, sys: 0 ns, total: 2.96 s\n",
      "Wall time: 2.71 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,     0,  7461,  4212],\n",
       "       [    0,     0,     0, ...,   440, 43852,  2966],\n",
       "       [    0,     0,     0, ...,     5,  1365,    89],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,     0,     0,     0],\n",
       "       [    0,     0,     0, ...,  1098,   690,  5036],\n",
       "       [    0,     0,     0, ...,  4021,  3828, 46158]], dtype=int32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pad_sequences(pad_sequences(q_df[:256000], maxlen=11), maxlen=10, truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  7461,  4212,     5],\n",
       "       [    0,     0,     0, ..., 43852,  2966,  2936],\n",
       "       [    0,     0,     0, ...,  1365,    89,  6772],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  9597,  1136,  1523],\n",
       "       [    0,     0,     0, ...,  6455, 11146, 13095],\n",
       "       [    0,     0,     0, ...,   978,  1440,  1584]], dtype=int32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([len(i) for i in np.concatenate([q_july, d_july, q_may, d_may])])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Sequential\n",
    "class W2V():\n",
    "    def __init__(self):\n",
    "        self.encoder = Sequential()\n",
    "\n",
    "        self.encoder.add(embedding_layer)\n",
    "        self.encoder.add(GlobalMaxPooling1D())\n",
    "\n",
    "w2v = W2V()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(max_len,))\n",
    "drop = Dropout(1.0)\n",
    "model = Model(inp, drop(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,   451,  4764,  2986],\n",
       "       [ 3354,    87, 14682, ...,   272,  2994, 26480],\n",
       "       [    0,     0,     0, ...,     4,  5901, 41148],\n",
       "       ...,\n",
       "       [    0,   564,  4966, ...,  1569,     2,  1268],\n",
       "       [    0,     0,     0, ...,     7,  2277,  3008],\n",
       "       [    0,     0,     0, ...,   587,   249,  2063]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(q_july).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "    \n",
    "        \n",
    "x_ = word_dropout(q_july, 0.75)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,   451,  4764,  2986],\n",
       "       [ 3354,    87, 14682, ...,   272,  2994, 26480],\n",
       "       [    0,     0,     0, ...,     4,  5901, 41148],\n",
       "       ...,\n",
       "       [    0,   564,  4966, ...,  1569,     2,  1268],\n",
       "       [    0,     0,     0, ...,     7,  2277,  3008],\n",
       "       [    0,     0,     0, ...,   587,   249,  2063]], dtype=int32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_july"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,   451,  4764,  2986],\n",
       "       [ 3354,    87, 14682, ..., 50509,  2994, 26480],\n",
       "       [    0,     0,     0, ...,     4,  5901, 50509],\n",
       "       ...,\n",
       "       [    0, 50509,  4966, ...,  1569,     2,  1268],\n",
       "       [    0,     0,     0, ...,     7, 50509,  3008],\n",
       "       [    0,     0,     0, ..., 50509,   249,  2063]], dtype=int32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A layer added to a Sequential model must not already be connected somewhere else. Model received layer embedding_2 which has 25 pre-existing inbound connections.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-53b3bb87553c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/t-jamano/.local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    448\u001b[0m                                  \u001b[0;34m' which has '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                                  ' pre-existing inbound connections.')\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A layer added to a Sequential model must not already be connected somewhere else. Model received layer embedding_2 which has 25 pre-existing inbound connections."
     ]
    }
   ],
   "source": [
    "encoder = Sequential()\n",
    "\n",
    "encoder.add(embedding_layer)\n",
    "encoder.add(GlobalAveragePooling1D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5147147202369183, 0.8371547445295584, 0.5832573550668237)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5237150474333905, 0.8425962550704119, 0.5428072672285352)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(max_len,))\n",
    "x_max = GlobalMaxPooling1D()(embedding_layer(inp))\n",
    "x_avg = GlobalAveragePooling1D()(embedding_layer(inp))\n",
    "m = merge([x_max, x_avg])\n",
    "both = Model(inp, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5187978233186405, 0.841557671534384, 0.5808001067401988)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(both, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5159227314797818, 0.8414010452141721, 0.5800885054148412)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(both, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Sequential.predict of <keras.models.Sequential object at 0x7fc565166eb8>>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.encoder.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tokens = np.unique(np.concatenate([q_july, d_july, q_may, d_may, q_june, d_june]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 23s, sys: 1min 22s, total: 23min 46s\n",
      "Wall time: 29min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count = 0\n",
    "file = open(\"/work/workspace/Texygen/data/1M_Query_GAN\", \"a+\") \n",
    "with open (\"/data/chzho/deepqts/train_data/unifiedclick/join_oneyearsample_2B_training_all_top10\", \"r\") as myfile:\n",
    "    for line in myfile:\n",
    "        s = line.split(\"\\t\")\n",
    "        market = s[5]\n",
    "        if \"en-\" not in market:\n",
    "            continue\n",
    "        \n",
    "#         re.sub(r'\\W+', ' ', s[1].lower())\n",
    "#         file.write(\"%s\\t%s\\t%s\\n\" % (s[0], re.sub(r'\\W+', ' ', s[1].lower()), re.sub(r'\\W+', ' ', s[3].lower())))\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "        if count > 1000000:\n",
    "            break\n",
    "        break\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27 s, sys: 376 ms, total: 27.4 s\n",
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count = 0\n",
    "file = open(\"/work/data/train_data/QueryQueryLog\", \"a+\") \n",
    "query = []\n",
    "with open (\"/work/data/train_data/1M_EN_QQ_log\", \"r\") as myfile:\n",
    "    for line in myfile:\n",
    "        s = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "#         print(line)\n",
    "        if len(s) < 2:\n",
    "            continue\n",
    "        tmp = s[1].split(\"<sep>\")\n",
    "        \n",
    "        __ = re.sub(r'\\W+', ' ', s[0].lower())\n",
    "        for i in tmp:\n",
    "            _ = re.sub(r'\\W+', ' ', i.lower())\n",
    "            \n",
    "            file.write(__+\"\\t\"+_+\"\\t1\\n\")\n",
    "        \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "count = 0\n",
    "file = open(\"/work/data/train_data/QueryLogBPE\", \"a+\") \n",
    "query = []\n",
    "with open (\"/work/data/train_data/1M_EN_QQ_log\", \"r\") as myfile:\n",
    "    for line in myfile:\n",
    "        s = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "#         print(line)\n",
    "        if len(s) < 2:\n",
    "            continue\n",
    "        tmp = s[1].split(\"<sep>\")\n",
    "        \n",
    "        __ = re.sub(r'\\W+', ' ', s[0].lower())\n",
    "        for i in tmp:\n",
    "            _ = re.sub(r'\\W+', ' ', i.lower())\n",
    "            \n",
    "            file.write(__+\"\\t\"+_+\"\\t1\\n\")\n",
    "        \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/work/data/train_data/QueryLog\", names=[\"q\"], sep=\"\\t\", header=None, error_bad_lines=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 696 ms, total: 1min 42s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_bpe_token = set([])\n",
    "for i in df.q.tolist():\n",
    "    for j in sp.EncodeAsPieces(i):\n",
    "        df_bpe_token.add(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561556"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_token = set([])\n",
    "july_token = set([])\n",
    "\n",
    "for i in df.q.tolist():\n",
    "    for j in i.split():\n",
    "        df_token.add(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 19898: expected 6 fields, saw 8\\nSkipping line 20620: expected 6 fields, saw 8\\nSkipping line 38039: expected 6 fields, saw 8\\n'\n"
     ]
    }
   ],
   "source": [
    "df_may, qrel_may = get_test_data(\"MayFlower\", \"/work/\")\n",
    "df_june, qrel_june = get_test_data(\"JuneFlower\", \"/work/\")\n",
    "df_july, qrel_july = get_test_data(\"JulyFlower\", \"/work/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Overlap between train and test dataset. QueryLog\n",
      "12853\n",
      "9648\n",
      "13351\n",
      "8799\n",
      "1372\n",
      "1310\n"
     ]
    }
   ],
   "source": [
    "print(\"Term Overlap between train and test dataset. QueryLog\")\n",
    "for a in [df_may, df_june, df_july]:\n",
    "    token = set([])\n",
    "    for i in a.q.tolist() + a.d.tolist():\n",
    "        for j in i.split():\n",
    "            token.add(j)\n",
    "    print(len(token))\n",
    "    print(len(df_token.intersection(token)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPE tokens overlap between train and test dataset. QueryLog\n",
      "11276\n",
      "10734\n",
      "10280\n",
      "10162\n",
      "1556\n",
      "1525\n"
     ]
    }
   ],
   "source": [
    "print(\"BPE tokens overlap between train and test dataset. QueryLog\")\n",
    "for a in [df_may, df_june, df_july]:\n",
    "    token = set([])\n",
    "    for i in a.q.tolist() + a.d.tolist():\n",
    "        for j in sp.EncodeAsPieces(i):\n",
    "            token.add(j)\n",
    "    print(len(token))\n",
    "    print(len(df_bpe_token.intersection(token)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/work/data/train_data/QueryLog\", names=[\"q\"], sep=\"\\t\", header=None, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 40s, sys: 1.76 s, total: 2min 42s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "q_df = parse_texts_bpe(df.q.tolist(), sp, bpe_dict, 5, enablePadding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test_reconstructed = np.random.randint(5, size=(1,5, 5))\n",
    "sent_idx = 0\n",
    "reconstructed_indexes = np.apply_along_axis(np.argmax, 1, x_test_reconstructed[sent_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3, 0, 0, 2, 4],\n",
       "        [2, 3, 4, 1, 1],\n",
       "        [1, 1, 2, 0, 2],\n",
       "        [0, 2, 4, 2, 1],\n",
       "        [4, 0, 3, 0, 4]]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.apply_along_axis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.random.randint(10, size=(1,4, 3))\n",
    "gen_y = np.argmax(a, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.apply_along_axis(np.argmax, 1, a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2, 7, 6],\n",
       "        [7, 5, 4],\n",
       "        [1, 3, 0],\n",
       "        [9, 5, 5]]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
