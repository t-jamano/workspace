{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Models import *\n",
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LETTER_GRAM_SIZE = 3 # See section 3.2.\n",
    "WINDOW_SIZE = 3 # See section 3.2.\n",
    "TOTAL_LETTER_GRAMS = 5005\n",
    "WORD_DEPTH = WINDOW_SIZE * TOTAL_LETTER_GRAMS # See equation (1).\n",
    "K = 300 # Dimensionality of the max-pooling layer. See section 3.4.\n",
    "L = 128 # Dimensionality of latent semantic space. See section 3.5.\n",
    "J = 1 # Number of random unclicked documents serving as negative examples for a query. See section 4.\n",
    "FILTER_LENGTH = 1 # We only consider one time step for convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dssm = DSSM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load pre-trained trigram\n",
    "tokeniser = L3wTransformer(TOTAL_LETTER_GRAMS)\n",
    "tokeniser = tokeniser.load(\"/work/data/trigram/2M_50k_trigram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_words = 50005\n",
    "max_len = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 19898: expected 6 fields, saw 8\\nSkipping line 20620: expected 6 fields, saw 8\\nSkipping line 38039: expected 6 fields, saw 8\\n'\n"
     ]
    }
   ],
   "source": [
    "df_may, qrel_may = get_test_data(\"MayFlower\")\n",
    "df_june, qrel_june = get_test_data(\"JuneFlower\")\n",
    "\n",
    "q_may = to_2D_one_hot(parse_texts(df_may.q.tolist(), tokeniser, max_len), nb_words)\n",
    "d_may = to_2D_one_hot(parse_texts(df_may.d.tolist(), tokeniser, max_len), nb_words)\n",
    "\n",
    "\n",
    "q_june = to_2D_one_hot(parse_texts(df_june.q.tolist(), tokeniser, max_len), nb_words)\n",
    "d_june = to_2D_one_hot(parse_texts(df_june.d.tolist(), tokeniser, max_len), nb_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 627s - loss: 0.3930\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/workspace/Models.py:26: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  pred = merge([q_input, d_input], mode=\"cos\")\n",
      "/home/t-jamano/.local/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG: 0.525413\n",
      "MAP: 0.510676\n",
      "NDCG: 0.810011\n",
      "MAP: 0.726695\n"
     ]
    }
   ],
   "source": [
    "file_dir = '/data/t-mipha/data/agi_encoder/v4/universal/CLICKED_QQ_EN_universal_train_1M.txt'\n",
    "\n",
    "reader = pd.read_csv(file_dir, chunksize=batch_size, iterator=True, usecols=[0,1], names=[\"q\", \"d\"], sep=\"\\t\", header=None, error_bad_lines=False)\n",
    "\n",
    "def qq_batch_generator(reader, tokeniser, batch_size, max_len, nb_words):\n",
    "    for df in reader:\n",
    "        q = df.q.tolist()\n",
    "        d = [i.split(\"<sep>\")[0] for i in df.d.tolist()]\n",
    "        \n",
    "        q = pad_sequences(tokeniser.texts_to_sequences(q), maxlen=max_len)\n",
    "        d = pad_sequences(tokeniser.texts_to_sequences(d), maxlen=max_len)\n",
    "        \n",
    "        q_one_hot = np.zeros((batch_size, nb_words))\n",
    "        for i in range(len(q)):\n",
    "            q_one_hot[i][q[i]] = 1\n",
    "            \n",
    "        d_one_hot = np.zeros((batch_size, nb_words))\n",
    "        for i in range(len(d)):\n",
    "            d_one_hot[i][d[i]] = 1\n",
    "            \n",
    "            \n",
    "        # negative sampling from positive pool\n",
    "        neg_d_one_hot = [[] for j in range(J)]\n",
    "        for i in range(batch_size):\n",
    "            possibilities = list(range(batch_size))\n",
    "            possibilities.remove(i)\n",
    "            negatives = np.random.choice(possibilities, J, replace = False)\n",
    "            for j in range(J):\n",
    "                negative = negatives[j]\n",
    "                neg_d_one_hot[j].append(d_one_hot[negative].tolist())\n",
    "        \n",
    "        y = np.zeros((batch_size, J + 1))\n",
    "        y[:, 0] = 1\n",
    "        \n",
    "        for j in range(J):\n",
    "            neg_d_one_hot[j] = np.array(neg_d_one_hot[j])\n",
    "        \n",
    "#         print(q_one_hot.shape, d_one_hot.shape, len(neg_d_one_hot))\n",
    "#         print(neg_d_one_hot[0])\n",
    "\n",
    "        # negative sampling from randomness\n",
    "        # for j in range(J):\n",
    "        #     neg_d_one_hot[j] = np.random.randint(2, size=(batch_size, 10, WORD_DEPTH))\n",
    "        \n",
    "\n",
    "#         q_one_hot = to_categorical(q, nb_words)   \n",
    "#         q_one_hot = q_one_hot.reshape(batch_size, max_len, nb_words)\n",
    "        \n",
    "        \n",
    "        yield [q_one_hot, d_one_hot] + [neg_d_one_hot[j] for j in range(J)], y\n",
    "\n",
    "        \n",
    "dssm.model.fit_generator(qq_batch_generator(reader, tokeniser, batch_size, max_len, nb_words), steps_per_epoch=1000, epochs=1, verbose=2, callbacks=[TQDMNotebookCallback()])       \n",
    "cosine = CosineSim(L)\n",
    "\n",
    "\n",
    "for q, d, qrel, df in [[q_may, d_may, qrel_may, df_may], [q_june, d_june, qrel_june, df_june]]:\n",
    "    pred = cosine.model.predict([dssm.encoder.predict(q), dssm.encoder.predict(d)])\n",
    "    pred = convert_2_trec(df.q.tolist(), df.d.tolist(), pred, False)\n",
    "    evaluate(qrel, pred)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/work/data/train_data/30M_EN_pos_qd_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_dir, usecols=[0,1], names=[\"q\", \"d\"], sep=\"\\t\", header=None, error_bad_lines=False)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_dir = '/data/chzho/deepqts/train_data/unifiedclick/join_oneyearsample_2B_training_all_top10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 11s, sys: 4min 14s, total: 21min 26s\n",
      "Wall time: 36min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(file_dir, nrows=100000000, usecols=[0,1,3,5], names=[\"label\", \"q\", \"d\", \"market\"], sep=\"\\t\", header=None, error_bad_lines=False)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[(df.market.str.contains(\"en-\")) & (df.label == 1)].to_csv(\"/work/data/train_data/EN_QD_log\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/work/data/train_data/1M_EN_qq_log\", usecols=[0,1], names=[\"q\", \"d\"], sep=\"\\t\", header=None, error_bad_lines=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "40121d45d796433e86f144da57aaca06": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "4f950df65bfa48a581245a4ad5d01396": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "4fdfd442819f466489d1c4df659a9b60": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "5cc02d76609d4684b99d1ddaa1a2465a": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "64a316a1aef54628961feaef24380dc8": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "78abecf8aea84794a100d19d09980b3c": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "81a8296ca0a744f194360836238c6426": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "8af57046991444389ee7dc2c83bbd5b3": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "9173a688fb4f47db96011a1f959dc8d2": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "928163f8c27e4c899e3556f903afcda8": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "9a0c8a1dc8d94f67a875c29a6bc0c5c1": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "9e8534108e404e648ab7711a1bf8c1df": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "b3bc4a01e2254d089cba417f9be0da1c": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "b7a76f91f5df4354af453325fd20d2fa": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "bddb4b8e61224c21b65cad00023b4c5f": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "e4a024990d4a4cf592614162b2e7126c": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "ec048682eaf44728b9309fc46ef0f586": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "f53ba99983484dd6b2941da3af6141eb": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "f808bda030fb48bbb6ecf14f19dbe615": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
